{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Video MCTF coding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../src/MCTF.py\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "%%writefile ../src/MCTF.py\n",
        "'''MCTF: Motion-Compensated Temporal Filtering with Hierarchical B-frames.\n",
        "\n",
        "Implementation features:\n",
        "- Bidirectional prediction for B-frames\n",
        "- Hierarchical B-frame structure\n",
        "- Integration with VCF spatial transforms (2D-DCT, 2D-DWT, etc.)\n",
        "- Reuses VCF quantizers, color transforms, and entropy codecs\n",
        "authors: Youssef Zerbouh, Hamza El Qadiri\n",
        "'''\n",
        "\n",
        "import sys\n",
        "import io\n",
        "import os\n",
        "import tempfile\n",
        "import logging\n",
        "import importlib\n",
        "import math\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import av\n",
        "from PIL import Image\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import multiprocessing as mp\n",
        "\n",
        "# VCF Framework\n",
        "with open(os.path.join(tempfile.gettempdir(), \"description.txt\"), 'w') as f:\n",
        "    f.write(__doc__)\n",
        "\n",
        "import main\n",
        "import parser\n",
        "import entropy_video_coding as EVC\n",
        "\n",
        "# =============================================================================\n",
        "# Constants and Configuration\n",
        "# =============================================================================\n",
        "\n",
        "class FrameType(Enum):\n",
        "    I = \"I\"  # Intra frame\n",
        "    P = \"P\"  # Predicted frame (forward only)\n",
        "    B = \"B\"  # Bidirectional frame\n",
        "\n",
        "@dataclass\n",
        "class MotionVector:\n",
        "    \"\"\"Motion vector with cost information.\"\"\"\n",
        "    dx: int\n",
        "    dy: int\n",
        "    sad: float\n",
        "    bits: float\n",
        "    cost: float\n",
        "    ref_idx: int  # Reference frame index\n",
        "\n",
        "@dataclass\n",
        "class EncodedFrame:\n",
        "    \"\"\"Frame encoding information.\"\"\"\n",
        "    frame_idx: int\n",
        "    frame_type: FrameType\n",
        "    display_order: int\n",
        "    encoding_order: int\n",
        "    references: List[int]  # Reference frame indices\n",
        "    data: Optional[np.ndarray] = None\n",
        "    mv_field: Optional[np.ndarray] = None\n",
        "    residual: Optional[np.ndarray] = None\n",
        "\n",
        "# =============================================================================\n",
        "# Arguments\n",
        "# =============================================================================\n",
        "\n",
        "DEFAULT_ENCODE_OUTPUT_PREFIX = os.path.join(tempfile.gettempdir(), \"encoded\")\n",
        "DEFAULT_DECODE_OUTPUT_PREFIX = os.path.join(tempfile.gettempdir(), \"decoded\")\n",
        "\n",
        "# Encoder - MCTF-specific parameters only\n",
        "# Note: -T (transform) is needed but not in VCF base parser, so we add it here\n",
        "parser.parser_encode.add_argument(\"-T\", \"--transform\", type=str,\n",
        "    help=f\"2D spatial transform for residuals (default: {EVC.DEFAULT_TRANSFORM})\",\n",
        "    default=EVC.DEFAULT_TRANSFORM)\n",
        "parser.parser_encode.add_argument(\"-M\", \"--block_size_ME\", type=parser.int_or_str,\n",
        "    help=\"Block size for motion estimation (default: 16)\",\n",
        "    default=16)\n",
        "parser.parser_encode.add_argument(\"-S\", \"--search_range\", type=parser.int_or_str,\n",
        "    help=\"Search range in pixels (default: 32)\",\n",
        "    default=32)\n",
        "parser.parser_encode.add_argument(\"--fast\", action=\"store_true\",\n",
        "    help=\"Use fast motion estimation (diamond search)\")\n",
        "parser.parser_encode.add_argument(\"--gop_size\", type=int,\n",
        "    help=\"GOP size (default: 16)\",\n",
        "    default=16)\n",
        "parser.parser_encode.add_argument(\"--num_gops\", type=int,\n",
        "    help=\"Number of GOPs to encode (default: 1)\",\n",
        "    default=1)\n",
        "parser.parser_encode.add_argument(\"--max_b_frames\", type=int,\n",
        "    help=\"Maximum consecutive B-frames (default: 10, minimum for prediction)\",\n",
        "    default=10)\n",
        "parser.parser_encode.add_argument(\"--hierarchical\", action=\"store_true\",\n",
        "    help=\"Use hierarchical B-frame structure\")\n",
        "parser.parser_encode.add_argument(\"--lambda_rd\", type=float,\n",
        "    help=\"Lagrange multiplier for RD optimization (default: 0.92*QSS). \"\n",
        "         \"Higher = favor rate, lower = favor distortion. 0 = pure SAD.\",\n",
        "    default=None)\n",
        "\n",
        "# Decoder - add transform parameter\n",
        "parser.parser_decode.add_argument(\"-T\", \"--transform\", type=str,\n",
        "    help=f\"2D spatial transform for residuals (default: {EVC.DEFAULT_TRANSFORM})\",\n",
        "    default=EVC.DEFAULT_TRANSFORM)\n",
        "\n",
        "# Parse and import transform\n",
        "args = parser.parser.parse_known_args()[0]\n",
        "\n",
        "# Get transform name - use VCF's default if not specified\n",
        "transform_name = getattr(args, 'transform', EVC.DEFAULT_TRANSFORM)\n",
        "\n",
        "if __debug__:\n",
        "    if args.debug:\n",
        "        print(f\"MCTF: Importing {transform_name}\")\n",
        "\n",
        "try:\n",
        "    transform = importlib.import_module(transform_name)\n",
        "except ImportError as e:\n",
        "    print(f\"Error: Could not find {transform_name} module ({e})\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# =============================================================================\n",
        "# Motion Estimation Utilities\n",
        "# =============================================================================\n",
        "\n",
        "def compute_sad(block1: np.ndarray, block2: np.ndarray) -> float:\n",
        "    \"\"\"Compute Sum of Absolute Differences between two blocks.\"\"\"\n",
        "    return float(np.sum(np.abs(block1.astype(np.int16) - block2.astype(np.int16))))\n",
        "\n",
        "def estimate_mv_bits(dx: int, dy: int) -> float:\n",
        "    \"\"\"Estimate bits to encode a motion vector using Exp-Golomb-like model.\n",
        "    \n",
        "    Each component costs  2·floor(log2(|v| + 1)) + 1  bits.\n",
        "    Zero MV = 2 bits total (cheapest), large MV = expensive.\n",
        "    \"\"\"\n",
        "    def _component_bits(v):\n",
        "        return 2.0 * math.floor(math.log2(abs(v) + 1)) + 1.0\n",
        "    return _component_bits(dx) + _component_bits(dy)\n",
        "\n",
        "# Bits to signal prediction mode in a B-frame block:\n",
        "#   fwd-only or bwd-only = 2 bits  (1 bit skip-bi + 1 bit direction)\n",
        "#   bidirectional        = 3 bits  (1 bit skip-bi + 2 MVs flag)\n",
        "MODE_BITS = {0: 2.0, 1: 2.0, 2: 3.0}\n",
        "\n",
        "# =============================================================================\n",
        "# Motion Estimation\n",
        "# =============================================================================\n",
        "\n",
        "def _diamond_search(ref_frame, curr_block, i, j, bs, sr=32, lmbda=0.0):\n",
        "    \"\"\"Diamond search pattern for motion estimation with RD cost.\n",
        "    \n",
        "    Minimises  J = SAD + λ · estimate_mv_bits(dx, dy).\n",
        "    Returns (best_mv, best_sad)  — the raw SAD of the winner\n",
        "    so callers can still use it for further mode decisions.\n",
        "    \"\"\"\n",
        "    h, w = ref_frame.shape[:2]\n",
        "    \n",
        "    # Large diamond pattern\n",
        "    ldp = [(0, -2), (-1, -1), (1, -1), (-2, 0), (2, 0), (-1, 1), (1, 1), (0, 2)]\n",
        "    # Small diamond pattern\n",
        "    sdp = [(0, -1), (-1, 0), (1, 0), (0, 1)]\n",
        "    \n",
        "    cx, cy = j, i\n",
        "    best_mv = (0, 0)\n",
        "    best_sad = float('inf')\n",
        "    best_cost = float('inf')\n",
        "    \n",
        "    # Evaluate center position (MV = (0,0), cheapest rate)\n",
        "    if 0 <= cy and cy + bs <= h and 0 <= cx and cx + bs <= w:\n",
        "        best_sad = compute_sad(curr_block, ref_frame[cy:cy+bs, cx:cx+bs])\n",
        "        best_cost = best_sad + lmbda * estimate_mv_bits(0, 0)\n",
        "    \n",
        "    # Large diamond search\n",
        "    improved = True\n",
        "    while improved:\n",
        "        improved = False\n",
        "        for ddx, ddy in ldp:\n",
        "            ry, rx = cy + ddy, cx + ddx\n",
        "            if (ry < 0 or ry + bs > h or rx < 0 or rx + bs > w or\n",
        "                abs(rx - j) > sr or abs(ry - i) > sr):\n",
        "                continue\n",
        "            \n",
        "            sad = compute_sad(curr_block, ref_frame[ry:ry+bs, rx:rx+bs])\n",
        "            mv_dx, mv_dy = rx - j, ry - i\n",
        "            cost = sad + lmbda * estimate_mv_bits(mv_dx, mv_dy)\n",
        "            \n",
        "            if cost < best_cost:\n",
        "                best_sad = sad\n",
        "                best_cost = cost\n",
        "                best_mv = (mv_dx, mv_dy)\n",
        "                cx, cy = rx, ry\n",
        "                improved = True\n",
        "    \n",
        "    # Small diamond search refinement\n",
        "    improved = True\n",
        "    while improved:\n",
        "        improved = False\n",
        "        for ddx, ddy in sdp:\n",
        "            ry, rx = cy + ddy, cx + ddx\n",
        "            if (ry < 0 or ry + bs > h or rx < 0 or rx + bs > w or\n",
        "                abs(rx - j) > sr or abs(ry - i) > sr):\n",
        "                continue\n",
        "            \n",
        "            sad = compute_sad(curr_block, ref_frame[ry:ry+bs, rx:rx+bs])\n",
        "            mv_dx, mv_dy = rx - j, ry - i\n",
        "            cost = sad + lmbda * estimate_mv_bits(mv_dx, mv_dy)\n",
        "            \n",
        "            if cost < best_cost:\n",
        "                best_sad = sad\n",
        "                best_cost = cost\n",
        "                best_mv = (mv_dx, mv_dy)\n",
        "                cx, cy = rx, ry\n",
        "                improved = True\n",
        "    \n",
        "    return best_mv, best_sad\n",
        "\n",
        "def _exhaustive_search(ref_frame, curr_block, i, j, bs, sr=32, lmbda=0.0):\n",
        "    \"\"\"Exhaustive search for motion estimation with RD cost.\n",
        "    \n",
        "    Minimises  J = SAD + λ · estimate_mv_bits(dx, dy).\n",
        "    \"\"\"\n",
        "    h, w = ref_frame.shape[:2]\n",
        "    best_mv = (0, 0)\n",
        "    best_sad = float('inf')\n",
        "    best_cost = float('inf')\n",
        "    \n",
        "    for dy in range(-sr, sr + 1):\n",
        "        for dx in range(-sr, sr + 1):\n",
        "            ry, rx = i + dy, j + dx\n",
        "            if 0 <= ry and ry + bs <= h and 0 <= rx and rx + bs <= w:\n",
        "                sad = compute_sad(curr_block, ref_frame[ry:ry+bs, rx:rx+bs])\n",
        "                cost = sad + lmbda * estimate_mv_bits(dx, dy)\n",
        "                \n",
        "                if cost < best_cost:\n",
        "                    best_sad = sad\n",
        "                    best_cost = cost\n",
        "                    best_mv = (dx, dy)\n",
        "    \n",
        "    return best_mv, best_sad\n",
        "\n",
        "def _process_block(args_tuple):\n",
        "    \"\"\"Process a single block for motion estimation (for parallel execution).\"\"\"\n",
        "    ref, curr_block, i, j, bs, sr, fast, lmbda = args_tuple\n",
        "    \n",
        "    if fast:\n",
        "        mv, sad = _diamond_search(ref, curr_block, i, j, bs, sr, lmbda)\n",
        "    else:\n",
        "        mv, sad = _exhaustive_search(ref, curr_block, i, j, bs, sr, lmbda)\n",
        "    \n",
        "    return mv, sad\n",
        "\n",
        "def _process_row(args_tuple):\n",
        "    \"\"\"Process one row of blocks for motion estimation.\"\"\"\n",
        "    ref, curr, i, bs, sr, w, fast, lmbda = args_tuple\n",
        "    mvs = []\n",
        "    sads = []\n",
        "    \n",
        "    for j in range(0, w - bs + 1, bs):\n",
        "        block = curr[i:i+bs, j:j+bs]\n",
        "        \n",
        "        if fast:\n",
        "            mv, sad = _diamond_search(ref, block, i, j, bs, sr, lmbda)\n",
        "        else:\n",
        "            mv, sad = _exhaustive_search(ref, block, i, j, bs, sr, lmbda)\n",
        "        \n",
        "        mvs.append(mv)\n",
        "        sads.append(sad)\n",
        "    \n",
        "    return mvs, sads\n",
        "\n",
        "def block_matching(ref_frame, curr_frame, bs=16, sr=32, fast=True, lmbda=0.0):\n",
        "    \"\"\"Block-based motion estimation with RD-optimised MV selection.\n",
        "    \n",
        "    Each block minimises  J = SAD + λ · R_mv  instead of pure SAD.\n",
        "    \"\"\"\n",
        "    ref_gray = cv2.cvtColor(ref_frame, cv2.COLOR_RGB2GRAY)\n",
        "    curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_RGB2GRAY)\n",
        "    h, w = ref_gray.shape\n",
        "    \n",
        "    mv_h = (h - bs) // bs + 1\n",
        "    mv_w = (w - bs) // bs + 1\n",
        "    mv_field = np.zeros((mv_h, mv_w, 2), dtype=np.float32)\n",
        "    \n",
        "    # For exhaustive search, use multiprocessing; for fast search, use threading\n",
        "    if not fast and sr > 16:\n",
        "        # Exhaustive search with large search range - use multiprocessing\n",
        "        from multiprocessing import Pool\n",
        "        \n",
        "        # Create block tasks\n",
        "        block_args = []\n",
        "        for i in range(0, h - bs + 1, bs):\n",
        "            for j in range(0, w - bs + 1, bs):\n",
        "                block = curr_gray[i:i+bs, j:j+bs]\n",
        "                block_args.append((ref_gray, block, i, j, bs, sr, fast, lmbda))\n",
        "        \n",
        "        # Process blocks in parallel\n",
        "        with Pool(processes=mp.cpu_count()) as pool:\n",
        "            results = pool.map(_process_block, block_args)\n",
        "        \n",
        "        # Reshape results into MV field\n",
        "        idx = 0\n",
        "        for ri in range(mv_h):\n",
        "            for ci in range(mv_w):\n",
        "                mv_field[ri, ci] = results[idx][0]\n",
        "                idx += 1\n",
        "    else:\n",
        "        # Fast search or small search range - use threading (row-based)\n",
        "        row_args = [(ref_gray, curr_gray, i, bs, sr, w, fast, lmbda) \n",
        "                    for i in range(0, h - bs + 1, bs)]\n",
        "        \n",
        "        with ThreadPoolExecutor(max_workers=max(1, mp.cpu_count() - 1)) as ex:\n",
        "            results = list(ex.map(_process_row, row_args))\n",
        "        \n",
        "        for ri, (row_mvs, row_sads) in enumerate(results):\n",
        "            for ci, mv in enumerate(row_mvs):\n",
        "                mv_field[ri, ci] = mv\n",
        "    \n",
        "    return mv_field\n",
        "\n",
        "# =============================================================================\n",
        "# Bidirectional Motion Estimation\n",
        "# =============================================================================\n",
        "\n",
        "def _process_bidir_block(args_tuple):\n",
        "    \"\"\"Process bidirectional ME for a single block with RD-optimised mode decision.\n",
        "    \n",
        "    Mode decision minimises  J = SAD + λ · (mv_bits + mode_bits).\n",
        "    \"\"\"\n",
        "    past_gray, future_gray, curr_block, i, j, bs, sr, fast, h, w, lmbda = args_tuple\n",
        "    \n",
        "    # Forward prediction (from past)\n",
        "    if fast:\n",
        "        mv_fwd, sad_fwd = _diamond_search(past_gray, curr_block, i, j, bs, sr, lmbda)\n",
        "    else:\n",
        "        mv_fwd, sad_fwd = _exhaustive_search(past_gray, curr_block, i, j, bs, sr, lmbda)\n",
        "    \n",
        "    # Backward prediction (from future)\n",
        "    if fast:\n",
        "        mv_bwd, sad_bwd = _diamond_search(future_gray, curr_block, i, j, bs, sr, lmbda)\n",
        "    else:\n",
        "        mv_bwd, sad_bwd = _exhaustive_search(future_gray, curr_block, i, j, bs, sr, lmbda)\n",
        "    \n",
        "    # Bidirectional (average of both predictions)\n",
        "    ry_fwd = max(0, min(i + int(mv_fwd[1]), h - bs))\n",
        "    rx_fwd = max(0, min(j + int(mv_fwd[0]), w - bs))\n",
        "    ry_bwd = max(0, min(i + int(mv_bwd[1]), h - bs))\n",
        "    rx_bwd = max(0, min(j + int(mv_bwd[0]), w - bs))\n",
        "    \n",
        "    pred_fwd = past_gray[ry_fwd:ry_fwd+bs, rx_fwd:rx_fwd+bs]\n",
        "    pred_bwd = future_gray[ry_bwd:ry_bwd+bs, rx_bwd:rx_bwd+bs]\n",
        "    pred_bi = ((pred_fwd.astype(np.int16) + pred_bwd.astype(np.int16)) // 2).astype(np.uint8)\n",
        "    \n",
        "    sad_bi = compute_sad(curr_block, pred_bi)\n",
        "    \n",
        "    # RD cost for each mode:  J = SAD + λ · (mv_bits + mode_bits)\n",
        "    cost_fwd = sad_fwd + lmbda * (estimate_mv_bits(*mv_fwd) + MODE_BITS[0])\n",
        "    cost_bwd = sad_bwd + lmbda * (estimate_mv_bits(*mv_bwd) + MODE_BITS[1])\n",
        "    cost_bi  = sad_bi  + lmbda * (estimate_mv_bits(*mv_fwd) + estimate_mv_bits(*mv_bwd) + MODE_BITS[2])\n",
        "    \n",
        "    # Choose best mode based on RD cost\n",
        "    if cost_fwd <= cost_bwd and cost_fwd <= cost_bi:\n",
        "        mode = 0  # Forward\n",
        "        mv_f = mv_fwd\n",
        "        mv_b = (0, 0)\n",
        "    elif cost_bwd <= cost_bi:\n",
        "        mode = 1  # Backward\n",
        "        mv_f = (0, 0)\n",
        "        mv_b = mv_bwd\n",
        "    else:\n",
        "        mode = 2  # Bidirectional\n",
        "        mv_f = mv_fwd\n",
        "        mv_b = mv_bwd\n",
        "    \n",
        "    return mv_f, mv_b, mode\n",
        "\n",
        "def bidirectional_me(ref_past, ref_future, curr_frame, bs=16, sr=32, fast=True, lmbda=0.0):\n",
        "    \"\"\"\n",
        "    Bidirectional motion estimation for B-frames with RD-optimised mode decision.\n",
        "    \n",
        "    MV selection minimises  J = SAD + λ · R_mv.\n",
        "    Mode decision minimises  J = SAD + λ · (R_mv + R_mode).\n",
        "    Returns forward MV, backward MV, and best mode (forward/backward/bi).\n",
        "    \"\"\"\n",
        "    h, w = curr_frame.shape[:2]\n",
        "    curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_RGB2GRAY)\n",
        "    past_gray = cv2.cvtColor(ref_past, cv2.COLOR_RGB2GRAY)\n",
        "    future_gray = cv2.cvtColor(ref_future, cv2.COLOR_RGB2GRAY)\n",
        "    \n",
        "    mv_h = (h - bs) // bs + 1\n",
        "    mv_w = (w - bs) // bs + 1\n",
        "    \n",
        "    mv_forward = np.zeros((mv_h, mv_w, 2), dtype=np.float32)\n",
        "    mv_backward = np.zeros((mv_h, mv_w, 2), dtype=np.float32)\n",
        "    mode = np.zeros((mv_h, mv_w), dtype=np.uint8)  # 0=fwd, 1=bwd, 2=bi\n",
        "    \n",
        "    # For exhaustive search, use multiprocessing\n",
        "    if not fast and sr > 16:\n",
        "        from multiprocessing import Pool\n",
        "        \n",
        "        # Create block tasks\n",
        "        block_args = []\n",
        "        for i in range(0, h - bs + 1, bs):\n",
        "            for j in range(0, w - bs + 1, bs):\n",
        "                curr_block = curr_gray[i:i+bs, j:j+bs]\n",
        "                block_args.append((past_gray, future_gray, curr_block, i, j, bs, sr, fast, h, w, lmbda))\n",
        "        \n",
        "        # Process blocks in parallel\n",
        "        with Pool(processes=mp.cpu_count()) as pool:\n",
        "            results = pool.map(_process_bidir_block, block_args)\n",
        "        \n",
        "        # Reshape results\n",
        "        idx = 0\n",
        "        for ri in range(mv_h):\n",
        "            for ci in range(mv_w):\n",
        "                mv_forward[ri, ci] = results[idx][0]\n",
        "                mv_backward[ri, ci] = results[idx][1]\n",
        "                mode[ri, ci] = results[idx][2]\n",
        "                idx += 1\n",
        "    else:\n",
        "        # Fast search - use sequential processing\n",
        "        for i in range(0, h - bs + 1, bs):\n",
        "            for j in range(0, w - bs + 1, bs):\n",
        "                curr_block = curr_gray[i:i+bs, j:j+bs]\n",
        "                \n",
        "                # Forward prediction (from past)\n",
        "                if fast:\n",
        "                    mv_fwd, sad_fwd = _diamond_search(past_gray, curr_block, i, j, bs, sr, lmbda)\n",
        "                else:\n",
        "                    mv_fwd, sad_fwd = _exhaustive_search(past_gray, curr_block, i, j, bs, sr, lmbda)\n",
        "                \n",
        "                # Backward prediction (from future)\n",
        "                if fast:\n",
        "                    mv_bwd, sad_bwd = _diamond_search(future_gray, curr_block, i, j, bs, sr, lmbda)\n",
        "                else:\n",
        "                    mv_bwd, sad_bwd = _exhaustive_search(future_gray, curr_block, i, j, bs, sr, lmbda)\n",
        "                \n",
        "                # Bidirectional (average of both)\n",
        "                ry_fwd = max(0, min(i + int(mv_fwd[1]), h - bs))\n",
        "                rx_fwd = max(0, min(j + int(mv_fwd[0]), w - bs))\n",
        "                ry_bwd = max(0, min(i + int(mv_bwd[1]), h - bs))\n",
        "                rx_bwd = max(0, min(j + int(mv_bwd[0]), w - bs))\n",
        "                \n",
        "                pred_fwd = past_gray[ry_fwd:ry_fwd+bs, rx_fwd:rx_fwd+bs]\n",
        "                pred_bwd = future_gray[ry_bwd:ry_bwd+bs, rx_bwd:rx_bwd+bs]\n",
        "                pred_bi = ((pred_fwd.astype(np.int16) + pred_bwd.astype(np.int16)) // 2).astype(np.uint8)\n",
        "                \n",
        "                sad_bi = compute_sad(curr_block, pred_bi)\n",
        "                \n",
        "                # RD cost for each mode:  J = SAD + λ · (mv_bits + mode_bits)\n",
        "                cost_fwd = sad_fwd + lmbda * (estimate_mv_bits(*mv_fwd) + MODE_BITS[0])\n",
        "                cost_bwd = sad_bwd + lmbda * (estimate_mv_bits(*mv_bwd) + MODE_BITS[1])\n",
        "                cost_bi  = sad_bi  + lmbda * (estimate_mv_bits(*mv_fwd) + estimate_mv_bits(*mv_bwd) + MODE_BITS[2])\n",
        "                \n",
        "                # Choose best mode based on RD cost\n",
        "                ri, ci = i // bs, j // bs\n",
        "                if cost_fwd <= cost_bwd and cost_fwd <= cost_bi:\n",
        "                    mode[ri, ci] = 0  # Forward\n",
        "                    mv_forward[ri, ci] = mv_fwd\n",
        "                    mv_backward[ri, ci] = (0, 0)\n",
        "                elif cost_bwd <= cost_bi:\n",
        "                    mode[ri, ci] = 1  # Backward\n",
        "                    mv_forward[ri, ci] = (0, 0)\n",
        "                    mv_backward[ri, ci] = mv_bwd\n",
        "                else:\n",
        "                    mode[ri, ci] = 2  # Bidirectional\n",
        "                    mv_forward[ri, ci] = mv_fwd\n",
        "                    mv_backward[ri, ci] = mv_bwd\n",
        "    \n",
        "    return mv_forward, mv_backward, mode\n",
        "\n",
        "# =============================================================================\n",
        "# Motion Compensation\n",
        "# =============================================================================\n",
        "\n",
        "def motion_compensate(frame, mv_field, bs=16, direction=1):\n",
        "    \"\"\"Apply motion compensation (single reference).\"\"\"\n",
        "    h, w = frame.shape[:2]\n",
        "    comp = np.zeros_like(frame)\n",
        "    \n",
        "    for i in range(0, h - bs + 1, bs):\n",
        "        for j in range(0, w - bs + 1, bs):\n",
        "            mv = mv_field[i // bs, j // bs] * direction\n",
        "            ry = int(np.clip(i + mv[1], 0, h - bs))\n",
        "            rx = int(np.clip(j + mv[0], 0, w - bs))\n",
        "            comp[i:i+bs, j:j+bs] = frame[ry:ry+bs, rx:rx+bs]\n",
        "    \n",
        "    # Handle boundaries\n",
        "    if h % bs != 0:\n",
        "        comp[-(h % bs):, :] = frame[-(h % bs):, :]\n",
        "    if w % bs != 0:\n",
        "        comp[:, -(w % bs):] = frame[:, -(w % bs):]\n",
        "    \n",
        "    return comp\n",
        "\n",
        "def motion_compensate_bidirectional(ref_past, ref_future, mv_fwd, mv_bwd, \n",
        "                                   mode, bs=16):\n",
        "    \"\"\"Apply bidirectional motion compensation.\"\"\"\n",
        "    h, w = ref_past.shape[:2]\n",
        "    comp = np.zeros_like(ref_past)\n",
        "    \n",
        "    for i in range(0, h - bs + 1, bs):\n",
        "        for j in range(0, w - bs + 1, bs):\n",
        "            ri, ci = i // bs, j // bs\n",
        "            m = mode[ri, ci]\n",
        "            \n",
        "            if m == 0:  # Forward only\n",
        "                mv = mv_fwd[ri, ci]\n",
        "                ry = int(np.clip(i + mv[1], 0, h - bs))\n",
        "                rx = int(np.clip(j + mv[0], 0, w - bs))\n",
        "                comp[i:i+bs, j:j+bs] = ref_past[ry:ry+bs, rx:rx+bs]\n",
        "            \n",
        "            elif m == 1:  # Backward only\n",
        "                mv = mv_bwd[ri, ci]\n",
        "                ry = int(np.clip(i + mv[1], 0, h - bs))\n",
        "                rx = int(np.clip(j + mv[0], 0, w - bs))\n",
        "                comp[i:i+bs, j:j+bs] = ref_future[ry:ry+bs, rx:rx+bs]\n",
        "            \n",
        "            else:  # Bidirectional\n",
        "                mv_f = mv_fwd[ri, ci]\n",
        "                mv_b = mv_bwd[ri, ci]\n",
        "                ry_f = int(np.clip(i + mv_f[1], 0, h - bs))\n",
        "                rx_f = int(np.clip(j + mv_f[0], 0, w - bs))\n",
        "                ry_b = int(np.clip(i + mv_b[1], 0, h - bs))\n",
        "                rx_b = int(np.clip(j + mv_b[0], 0, w - bs))\n",
        "                \n",
        "                pred_f = ref_past[ry_f:ry_f+bs, rx_f:rx_f+bs]\n",
        "                pred_b = ref_future[ry_b:ry_b+bs, rx_b:rx_b+bs]\n",
        "                comp[i:i+bs, j:j+bs] = ((pred_f.astype(np.int16) + \n",
        "                                        pred_b.astype(np.int16)) // 2).astype(np.uint8)\n",
        "    \n",
        "    # Handle boundaries\n",
        "    if h % bs != 0:\n",
        "        comp[-(h % bs):, :] = ref_past[-(h % bs):, :]\n",
        "    if w % bs != 0:\n",
        "        comp[:, -(w % bs):] = ref_past[:, -(w % bs):]\n",
        "    \n",
        "    return comp\n",
        "\n",
        "# =============================================================================\n",
        "# GOP Structure Management\n",
        "# =============================================================================\n",
        "\n",
        "def create_hierarchical_gop(gop_size: int, max_b_frames: int = 3) -> List[EncodedFrame]:\n",
        "    \"\"\"\n",
        "    Create hierarchical B-frame GOP structure.\n",
        "    \n",
        "    Example for GOP=8, max_b=3:\n",
        "    Display:  0  1  2  3  4  5  6  7  8\n",
        "    Type:     I  B  B  B  P  B  B  B  I\n",
        "    Encoding: 0  4  2  1  3  8  6  5  7\n",
        "    Level:    0  2  1  2  0  2  1  2  0\n",
        "    \"\"\"\n",
        "    frames = []\n",
        "    display_order = 0\n",
        "    \n",
        "    # I-frame at start\n",
        "    frames.append(EncodedFrame(\n",
        "        frame_idx=0,\n",
        "        frame_type=FrameType.I,\n",
        "        display_order=0,\n",
        "        encoding_order=0,\n",
        "        references=[]\n",
        "    ))\n",
        "    display_order += 1\n",
        "    \n",
        "    # P or I frame at end of GOP\n",
        "    if gop_size > 1:\n",
        "        frames.append(EncodedFrame(\n",
        "            frame_idx=gop_size - 1,\n",
        "            frame_type=FrameType.P,\n",
        "            display_order=gop_size - 1,\n",
        "            encoding_order=1,\n",
        "            references=[0]\n",
        "        ))\n",
        "        \n",
        "        # Hierarchical B-frames\n",
        "        def add_hierarchical_b(start_ref, end_ref, level, encoding_order):\n",
        "            if end_ref - start_ref <= 1:\n",
        "                return encoding_order\n",
        "            \n",
        "            mid = (start_ref + end_ref) // 2\n",
        "            frames.append(EncodedFrame(\n",
        "                frame_idx=mid,\n",
        "                frame_type=FrameType.B,\n",
        "                display_order=mid,\n",
        "                encoding_order=encoding_order,\n",
        "                references=[start_ref, end_ref]\n",
        "            ))\n",
        "            encoding_order += 1\n",
        "            \n",
        "            if level < max_b_frames:\n",
        "                encoding_order = add_hierarchical_b(start_ref, mid, level + 1, encoding_order)\n",
        "                encoding_order = add_hierarchical_b(mid, end_ref, level + 1, encoding_order)\n",
        "            \n",
        "            return encoding_order\n",
        "        \n",
        "        add_hierarchical_b(0, gop_size - 1, 1, 2)\n",
        "    \n",
        "    # Sort by encoding order\n",
        "    frames.sort(key=lambda x: x.encoding_order)\n",
        "    \n",
        "    return frames\n",
        "\n",
        "def create_simple_gop(gop_size: int, max_b_frames: int = 3) -> List[EncodedFrame]:\n",
        "    \"\"\"\n",
        "    Create simple IBBP GOP structure.\n",
        "    \n",
        "    Example for GOP=8, max_b=3:\n",
        "    Display:  0  1  2  3  4  5  6  7  8\n",
        "    Type:     I  B  B  B  P  B  B  B  I\n",
        "    Encoding: 0  4  1  2  3  8  5  6  7\n",
        "    \"\"\"\n",
        "    frames = []\n",
        "    \n",
        "    # I-frame at start\n",
        "    frames.append(EncodedFrame(\n",
        "        frame_idx=0,\n",
        "        frame_type=FrameType.I,\n",
        "        display_order=0,\n",
        "        encoding_order=0,\n",
        "        references=[]\n",
        "    ))\n",
        "    \n",
        "    # P or I frame at end of GOP\n",
        "    if gop_size > 1:\n",
        "        anchor_pos = gop_size - 1\n",
        "        frames.append(EncodedFrame(\n",
        "            frame_idx=anchor_pos,\n",
        "            frame_type=FrameType.P,\n",
        "            display_order=anchor_pos,\n",
        "            encoding_order=1,\n",
        "            references=[0]  # Reference I-frame\n",
        "        ))\n",
        "        \n",
        "        # All B-frames reference I and P\n",
        "        encoding_order = 2\n",
        "        for b_pos in range(1, anchor_pos):\n",
        "            frames.append(EncodedFrame(\n",
        "                frame_idx=b_pos,\n",
        "                frame_type=FrameType.B,\n",
        "                display_order=b_pos,\n",
        "                encoding_order=encoding_order,\n",
        "                references=[0, anchor_pos]  # All B-frames reference (I, P)\n",
        "            ))\n",
        "            encoding_order += 1\n",
        "    \n",
        "    # Sort by encoding order\n",
        "    frames.sort(key=lambda x: x.encoding_order)\n",
        "    \n",
        "    return frames\n",
        "\n",
        "# =============================================================================\n",
        "# CoDec Class\n",
        "# =============================================================================\n",
        "\n",
        "class CoDec(EVC.CoDec):\n",
        "    \"\"\"MCTF Codec with hierarchical B-frames using VCF framework transforms.\"\"\"\n",
        "\n",
        "    def __init__(self, args):\n",
        "        logging.debug(\"trace\")\n",
        "        super().__init__(args)\n",
        "        self.transform_codec = transform.CoDec(args)\n",
        "        logging.info(f\"Using {args.transform} spatial transform for residuals\")\n",
        "        \n",
        "        # Pass QSS to transform codec if available\n",
        "        if hasattr(args, 'QSS'):\n",
        "            self.transform_codec.args.QSS = args.QSS\n",
        "            logging.info(f\"Set transform codec QSS to {args.QSS}\")\n",
        "            # Recreate the quantizer with the correct QSS\n",
        "            # (transform codec's __init__ already created it with possibly wrong QSS)\n",
        "            try:\n",
        "                from scalar_quantization.deadzone_quantization import Deadzone_Quantizer\n",
        "                self.transform_codec.Q = Deadzone_Quantizer(Q_step=args.QSS, min_val=0, max_val=255)\n",
        "                logging.info(f\"Recreated quantizer with QSS={args.QSS}\")\n",
        "            except Exception as e:\n",
        "                logging.warning(f\"Could not recreate quantizer: {e}\")\n",
        "        \n",
        "        # Monkey-patch transform codec methods to use self.args when called without arguments\n",
        "        # This fixes VCF framework's encode()/decode() which call these without args\n",
        "        # Also capture decoded output in case decode_write fails to persist to disk\n",
        "        self._captured_decode_output = [None]\n",
        "        original_encode_read = self.transform_codec.encode_read\n",
        "        original_encode_write = self.transform_codec.encode_write\n",
        "        original_decode_read = self.transform_codec.decode_read\n",
        "        original_decode_write = self.transform_codec.decode_write\n",
        "        \n",
        "        def patched_encode_read(fn=None):\n",
        "            if fn is None:\n",
        "                fn = self.transform_codec.args.original\n",
        "            return original_encode_read(fn)\n",
        "        \n",
        "        def patched_encode_write(codestream, fn=None):\n",
        "            if fn is None:\n",
        "                fn = self.transform_codec.args.encoded\n",
        "            return original_encode_write(codestream, fn)\n",
        "        \n",
        "        def patched_decode_read(fn=None):\n",
        "            if fn is None:\n",
        "                fn = self.transform_codec.args.encoded\n",
        "            return original_decode_read(fn)\n",
        "        \n",
        "        def patched_decode_write(img, fn=None):\n",
        "            if fn is None:\n",
        "                fn = self.transform_codec.args.decoded\n",
        "            self._captured_decode_output[0] = np.array(img, copy=True)\n",
        "            return original_decode_write(img, fn)\n",
        "        \n",
        "        self.transform_codec.encode_read = patched_encode_read\n",
        "        self.transform_codec.encode_write = patched_encode_write\n",
        "        self.transform_codec.decode_read = patched_decode_read\n",
        "        self.transform_codec.decode_write = patched_decode_write\n",
        "        \n",
        "        self.block_size = int(getattr(args, 'block_size_ME', 16))\n",
        "        self.search_range = int(getattr(args, 'search_range', 32))\n",
        "        self.fast = getattr(args, 'fast', False)\n",
        "        self.gop_size = int(getattr(args, 'gop_size', 16))\n",
        "        self.num_gops = int(getattr(args, 'num_gops', 1))\n",
        "        self.max_b_frames = int(getattr(args, 'max_b_frames', 10))\n",
        "        self.hierarchical = getattr(args, 'hierarchical', False)\n",
        "        \n",
        "        # Ensure we have at least 10 frames for prediction\n",
        "        if self.max_b_frames < 10:\n",
        "            logging.warning(f\"max_b_frames={self.max_b_frames} is too low, setting to 10\")\n",
        "            self.max_b_frames = 10\n",
        "        \n",
        "        # Where original frames are expected for metrics\n",
        "        self.original_prefix = getattr(args, \"original_prefix\",\n",
        "                                       os.path.join(tempfile.gettempdir(), \"encoded_original\"))\n",
        "        \n",
        "        # RD-optimization: λ controls the rate-distortion trade-off\n",
        "        #   J = SAD + λ · R   (λ=0 ⟹ pure SAD, higher λ ⟹ favor cheaper MVs)\n",
        "        # Default: √0.85 · QSS ≈ 0.92·QSS  (H.264 SAD-λ relationship)\n",
        "        user_lambda = getattr(args, 'lambda_rd', None)\n",
        "        if user_lambda is not None:\n",
        "            self.lambda_rd = float(user_lambda)\n",
        "        else:\n",
        "            qss = float(getattr(args, 'QSS', 1))\n",
        "            self.lambda_rd = math.sqrt(0.85) * qss\n",
        "        \n",
        "        logging.info(f\"MCTF Config: GOP={self.gop_size}, NumGOPs={self.num_gops}, MaxB={self.max_b_frames}, \"\n",
        "                    f\"BlockSize={self.block_size}, SearchRange={self.search_range}, \"\n",
        "                    f\"Fast={self.fast}, Hierarchical={self.hierarchical}, \"\n",
        "                    f\"λ_RD={self.lambda_rd:.4f}\")\n",
        "\n",
        "    def bye(self):\n",
        "        \"\"\"Override parent's bye() to prevent double video encoding.\"\"\"\n",
        "        logging.debug(\"trace\")\n",
        "        \n",
        "        # Only calculate metrics without re-encoding\n",
        "        if not self.encoding:\n",
        "            logging.info(\"MCTF: Skipping VCF's automatic video re-encoding (already done)\")\n",
        "\n",
        "    def encode(self):\n",
        "        \"\"\"Encode video with MCTF.\"\"\"\n",
        "        logging.debug(\"trace\")\n",
        "        fn = self.args.original\n",
        "        logging.info(f\"Encoding {fn}\")\n",
        "        \n",
        "        # Check if input is likely a video file\n",
        "        if fn.endswith('.png') or fn.endswith('.jpg') or fn.endswith('.jpeg'):\n",
        "            logging.error(f\"MCTF requires a video file (e.g., .mp4, .avi) as input, not an image file.\")\n",
        "            logging.error(f\"Received: {fn}\")\n",
        "            logging.error(\"Please use -o with a video file URL or path.\")\n",
        "            return 0\n",
        "        \n",
        "        try:\n",
        "            container = av.open(fn)\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Cannot open video file {fn}: {e}\")\n",
        "            logging.error(\"MCTF requires a video file (e.g., .mp4, .avi) as input.\")\n",
        "            return 0\n",
        "        \n",
        "        # Calculate total frames from gop_size * num_gops\n",
        "        total_frames_to_encode = self.gop_size * self.num_gops\n",
        "        logging.info(f\"Total frames to encode: {total_frames_to_encode} (GOP size={self.gop_size} × num GOPs={self.num_gops})\")\n",
        "        \n",
        "        # Read frames\n",
        "        frames = []\n",
        "        for packet in container.demux():\n",
        "            if __debug__:\n",
        "                self.total_input_size += packet.size\n",
        "            for frame in packet.decode():\n",
        "                img = np.array(frame.to_image().convert(\"RGB\"))\n",
        "                frames.append(img)\n",
        "                if len(frames) >= total_frames_to_encode:\n",
        "                    break\n",
        "            if len(frames) >= total_frames_to_encode:\n",
        "                break\n",
        "        container.close()\n",
        "        \n",
        "        if len(frames) < 2:\n",
        "            logging.error(\"Need at least 2 frames\")\n",
        "            return 0\n",
        "        \n",
        "        self.N_frames = len(frames)\n",
        "        self.height, self.width = frames[0].shape[:2]\n",
        "        self.N_channels = 3\n",
        "        # Force original frames to be saved in /tmp\n",
        "        self.original_prefix = os.path.join(tempfile.gettempdir(), \"encoded_original\")\n",
        "        \n",
        "        logging.info(f\"Video: {self.width}x{self.height}, {self.N_frames} frames, {self.N_channels} channels\")\n",
        "        \n",
        "        # Save original frames\n",
        "        for idx, img in enumerate(frames):\n",
        "            img_fn = f\"{self.original_prefix}_{idx:04d}.png\"\n",
        "            Image.fromarray(img).save(img_fn)\n",
        "        \n",
        "        # Process GOPs\n",
        "        decoded_frames = {}  # Cache for reference frames\n",
        "        \n",
        "        for gop_start in range(0, self.N_frames, self.gop_size):\n",
        "            gop_end = min(gop_start + self.gop_size, self.N_frames)\n",
        "            actual_gop_size = gop_end - gop_start\n",
        "            gop_start_size = self.total_output_size\n",
        "            \n",
        "            logging.info(f\"\\n{'='*60}\")\n",
        "            logging.info(f\"Processing GOP {gop_start}-{gop_end-1} (size={actual_gop_size})\")\n",
        "            logging.info(f\"{'='*60}\")\n",
        "            \n",
        "            # Create GOP structure\n",
        "            if self.hierarchical:\n",
        "                gop_structure = create_hierarchical_gop(actual_gop_size, self.max_b_frames)\n",
        "            else:\n",
        "                gop_structure = create_simple_gop(actual_gop_size, self.max_b_frames)\n",
        "            \n",
        "            # Encode frames in encoding order\n",
        "            i_count = p_count = b_count = 0\n",
        "            for frame_info in gop_structure:\n",
        "                abs_idx = gop_start + frame_info.frame_idx\n",
        "                if abs_idx >= self.N_frames:\n",
        "                    continue\n",
        "                \n",
        "                frame = frames[abs_idx]\n",
        "                \n",
        "                if frame_info.frame_type == FrameType.I:\n",
        "                    self._encode_i_frame(frame, abs_idx, decoded_frames)\n",
        "                    i_count += 1\n",
        "                \n",
        "                elif frame_info.frame_type == FrameType.P:\n",
        "                    ref_idx = gop_start + frame_info.references[0]\n",
        "                    self._encode_p_frame(frame, abs_idx, ref_idx, decoded_frames)\n",
        "                    p_count += 1\n",
        "                \n",
        "                elif frame_info.frame_type == FrameType.B:\n",
        "                    ref_past_idx = gop_start + frame_info.references[0]\n",
        "                    ref_future_idx = gop_start + frame_info.references[1]\n",
        "                    self._encode_b_frame(frame, abs_idx, ref_past_idx, \n",
        "                                       ref_future_idx, decoded_frames)\n",
        "                    b_count += 1\n",
        "            \n",
        "            # GOP statistics\n",
        "            gop_bytes = self.total_output_size - gop_start_size\n",
        "            gop_pixels = actual_gop_size * self.width * self.height\n",
        "            gop_bpp = (gop_bytes * 8) / gop_pixels if gop_pixels > 0 else 0\n",
        "            \n",
        "            logging.info(f\"\\nGOP {gop_start}-{gop_end-1} Summary:\")\n",
        "            logging.info(f\"  Frame types: I={i_count}, P={p_count}, B={b_count}\")\n",
        "            logging.info(f\"  GOP size: {gop_bytes} bytes ({gop_bpp:.4f} bpp)\")\n",
        "            logging.info(f\"  Average: {gop_bytes/actual_gop_size:.2f} bytes/frame\")\n",
        "        \n",
        "        logging.info(f\"\\n{'='*60}\")\n",
        "        logging.info(f\"ENCODING COMPLETE\")\n",
        "        logging.info(f\"{'='*60}\")\n",
        "        \n",
        "        # Calculate and log metrics\n",
        "        total_pixels = self.N_frames * self.width * self.height\n",
        "        BPP = (self.total_output_size * 8) / total_pixels\n",
        "        \n",
        "        logging.info(f\"Total frames encoded: {self.N_frames}\")\n",
        "        logging.info(f\"Video dimensions: {self.width}x{self.height}\")\n",
        "        logging.info(f\"Total output size: {self.total_output_size} bytes ({self.total_output_size/1024/1024:.2f} MB)\")\n",
        "        logging.info(f\"Total input size: {self.total_input_size} bytes ({self.total_input_size/1024/1024:.2f} MB)\")\n",
        "        logging.info(f\"Compression ratio: {self.total_input_size/self.total_output_size:.2f}:1\")\n",
        "        logging.info(f\"Total pixels: {total_pixels}\")\n",
        "        logging.info(f\"Bits Per Pixel (BPP): {BPP:.6f}\")\n",
        "        logging.info(f\"Compression rate: {BPP:.4f} bits/pixel\")\n",
        "        logging.info(f\"\\nNOTE: The encoded size ({self.total_output_size/1024/1024:.2f} MB) is the actual compressed data.\")\n",
        "        logging.info(f\"The decoded MP4 is for playback only and uses H.264 re-encoding.\")\n",
        "        logging.info(f\"{'='*60}\\n\")\n",
        "        \n",
        "        # Persist metadata so decode() is self-contained\n",
        "        with open(f\"{self.args.encoded}_meta.txt\", \"w\") as f:\n",
        "            f.write(f\"{self.original_prefix}\\n\")\n",
        "            f.write(f\"{self.N_frames}\\n\")\n",
        "            f.write(f\"{self.height}\\n\")\n",
        "            f.write(f\"{self.width}\\n\")\n",
        "            f.write(f\"{BPP}\\n\")\n",
        "            f.write(f\"{self.total_output_size}\\n\")\n",
        "        \n",
        "        return self.total_output_size\n",
        "\n",
        "    def _encode_i_frame(self, frame, idx, decoded_frames):\n",
        "        \"\"\"Encode I-frame.\"\"\"\n",
        "        logging.info(f\"Encoding I-frame {idx}\")\n",
        "        \n",
        "        i_orig_fn = f\"{self.args.encoded}_I_{idx:04d}.png\"\n",
        "        i_enc_fn = f\"{self.args.encoded}_{idx:04d}\"\n",
        "        Image.fromarray(frame).save(i_orig_fn)\n",
        "        \n",
        "        # Temporarily set args so transform codec's encode() reads/writes correct files\n",
        "        saved_original = getattr(self.transform_codec.args, 'original', None)\n",
        "        saved_encoded = getattr(self.transform_codec.args, 'encoded', None)\n",
        "        \n",
        "        self.transform_codec.args.original = i_orig_fn\n",
        "        self.transform_codec.args.encoded = i_enc_fn\n",
        "        \n",
        "        # Recreate quantizer with correct QSS before encoding\n",
        "        if hasattr(self.args, 'QSS'):\n",
        "            self.transform_codec.args.QSS = self.args.QSS\n",
        "            from scalar_quantization.deadzone_quantization import Deadzone_Quantizer\n",
        "            self.transform_codec.Q = Deadzone_Quantizer(Q_step=self.args.QSS, min_val=0, max_val=255)\n",
        "        \n",
        "        # Use full encode() to ensure DCT transform and quantization are applied\n",
        "        O_bytes = self.transform_codec.encode()\n",
        "        \n",
        "        # Restore args\n",
        "        if saved_original is not None:\n",
        "            self.transform_codec.args.original = saved_original\n",
        "        if saved_encoded is not None:\n",
        "            self.transform_codec.args.encoded = saved_encoded\n",
        "        \n",
        "        self.total_output_size += O_bytes\n",
        "        \n",
        "        # Save metadata\n",
        "        with open(f\"{i_enc_fn}_type.txt\", 'w') as f:\n",
        "            f.write(\"I\")\n",
        "        \n",
        "        # Decode and cache for references\n",
        "        dec_fn = f\"{self.args.encoded}_dec_{idx:04d}.png\"\n",
        "        saved_encoded = getattr(self.transform_codec.args, 'encoded', None)\n",
        "        saved_decoded = getattr(self.transform_codec.args, 'decoded', None)\n",
        "        \n",
        "        self.transform_codec.args.encoded = i_enc_fn\n",
        "        self.transform_codec.args.decoded = dec_fn\n",
        "        self._captured_decode_output[0] = None\n",
        "        self.transform_codec.decode()\n",
        "        \n",
        "        if saved_encoded is not None:\n",
        "            self.transform_codec.args.encoded = saved_encoded\n",
        "        if saved_decoded is not None:\n",
        "            self.transform_codec.args.decoded = saved_decoded\n",
        "        \n",
        "        # Use captured output if available (avoids FileNotFoundError when decode_write path differs)\n",
        "        if self._captured_decode_output[0] is not None:\n",
        "            decoded_frames[idx] = self._captured_decode_output[0]\n",
        "        elif os.path.exists(dec_fn):\n",
        "            decoded_frames[idx] = np.array(Image.open(dec_fn).convert(\"RGB\"))\n",
        "        else:\n",
        "            raise FileNotFoundError(\n",
        "                f\"Decoded frame not found at {dec_fn}. \"\n",
        "                \"The transform codec's decode() did not write the expected output.\"\n",
        "            )\n",
        "        \n",
        "        logging.info(f\"  I-frame {idx}: {O_bytes} bytes\")\n",
        "\n",
        "    def _encode_p_frame(self, frame, idx, ref_idx, decoded_frames):\n",
        "        \"\"\"Encode P-frame (forward prediction only) using VCF transform.\"\"\"\n",
        "        logging.info(f\"Encoding P-frame {idx} (ref={ref_idx})\")\n",
        "        \n",
        "        ref_frame = decoded_frames[ref_idx]\n",
        "        \n",
        "        # Motion estimation (RD-optimised: J = SAD + λ·R_mv)\n",
        "        mv_field = block_matching(\n",
        "            ref_frame, frame, \n",
        "            self.block_size, self.search_range, \n",
        "            self.fast, self.lambda_rd\n",
        "        )\n",
        "        \n",
        "        # Motion compensation\n",
        "        pred = motion_compensate(ref_frame, mv_field, self.block_size)\n",
        "        \n",
        "        # Compute residual and map to [0, 255] without hard-clipping:\n",
        "        # residual ∈ [-255, 255] → /2 + 128 → [0.5, 255.5] → round → [0, 255]\n",
        "        # Max rounding error from mapping: ±1 per sample (vs up to ±128 with old +128 clip)\n",
        "        residual = frame.astype(np.int16) - pred.astype(np.int16)\n",
        "        residual_img = np.clip(np.round(residual.astype(np.float32) / 2 + 128), 0, 255).astype(np.uint8)\n",
        "        \n",
        "        # Save residual as PNG and encode using transform codec (DCT + quantize + entropy)\n",
        "        residual_fn = f\"{self.args.encoded}_res_{idx:04d}.png\"\n",
        "        Image.fromarray(residual_img).save(residual_fn)\n",
        "        \n",
        "        enc_fn = f\"{self.args.encoded}_{idx:04d}\"\n",
        "        \n",
        "        # Temporarily set args\n",
        "        saved_original = getattr(self.transform_codec.args, 'original', None)\n",
        "        saved_encoded = getattr(self.transform_codec.args, 'encoded', None)\n",
        "        \n",
        "        self.transform_codec.args.original = residual_fn\n",
        "        self.transform_codec.args.encoded = enc_fn\n",
        "        \n",
        "        # Recreate quantizer before encoding\n",
        "        if hasattr(self.args, 'QSS'):\n",
        "            self.transform_codec.args.QSS = self.args.QSS\n",
        "            from scalar_quantization.deadzone_quantization import Deadzone_Quantizer\n",
        "            self.transform_codec.Q = Deadzone_Quantizer(Q_step=self.args.QSS, min_val=0, max_val=255)\n",
        "        \n",
        "        O_bytes = self.transform_codec.encode()\n",
        "        \n",
        "        # Restore args\n",
        "        if saved_original is not None:\n",
        "            self.transform_codec.args.original = saved_original\n",
        "        if saved_encoded is not None:\n",
        "            self.transform_codec.args.encoded = saved_encoded\n",
        "        \n",
        "        self.total_output_size += O_bytes\n",
        "        \n",
        "        # Save motion vectors\n",
        "        np.savez_compressed(\n",
        "            f\"{enc_fn}_mv.npz\",\n",
        "            mv=mv_field,\n",
        "            ref_idx=ref_idx\n",
        "        )\n",
        "        mv_size = os.path.getsize(f\"{enc_fn}_mv.npz\")\n",
        "        self.total_output_size += mv_size\n",
        "        \n",
        "        # Save frame type\n",
        "        with open(f\"{enc_fn}_type.txt\", 'w') as f:\n",
        "            f.write(f\"P:{ref_idx}\")\n",
        "        \n",
        "        # Decode residual to get reconstruction (encoder-side decode for reference)\n",
        "        dec_fn = f\"{self.args.encoded}_dec_{idx:04d}.png\"\n",
        "        saved_encoded = getattr(self.transform_codec.args, 'encoded', None)\n",
        "        saved_decoded = getattr(self.transform_codec.args, 'decoded', None)\n",
        "        \n",
        "        self.transform_codec.args.encoded = enc_fn\n",
        "        self.transform_codec.args.decoded = dec_fn\n",
        "        self._captured_decode_output[0] = None\n",
        "        self.transform_codec.decode()\n",
        "        \n",
        "        self.transform_codec.args.encoded = saved_encoded\n",
        "        self.transform_codec.args.decoded = saved_decoded\n",
        "        \n",
        "        # Undo mapping: (pixel - 128) * 2; use captured output if available\n",
        "        if self._captured_decode_output[0] is not None:\n",
        "            residual_img_dec = self._captured_decode_output[0]\n",
        "        elif os.path.exists(dec_fn):\n",
        "            residual_img_dec = np.array(Image.open(dec_fn).convert(\"RGB\"))\n",
        "        else:\n",
        "            raise FileNotFoundError(\n",
        "                f\"Decoded residual not found at {dec_fn}. \"\n",
        "                \"The transform codec's decode() did not write the expected output.\"\n",
        "            )\n",
        "        residual_rec = (residual_img_dec.astype(np.int16) - 128) * 2\n",
        "        \n",
        "        # Reconstruct and cache\n",
        "        recon = np.clip(pred.astype(np.int16) + residual_rec, 0, 255).astype(np.uint8)\n",
        "        decoded_frames[idx] = recon\n",
        "        \n",
        "        logging.info(f\"  P-frame {idx}: residual={O_bytes} bytes, mv={mv_size} bytes\")\n",
        "\n",
        "    def _encode_b_frame(self, frame, idx, ref_past_idx, ref_future_idx, decoded_frames):\n",
        "        \"\"\"Encode B-frame (bidirectional prediction) using VCF transform.\"\"\"\n",
        "        logging.info(f\"Encoding B-frame {idx} (refs={ref_past_idx},{ref_future_idx})\")\n",
        "        \n",
        "        ref_past = decoded_frames[ref_past_idx]\n",
        "        ref_future = decoded_frames[ref_future_idx]\n",
        "        \n",
        "        # Bidirectional motion estimation (RD-optimised: J = SAD + λ·(R_mv + R_mode))\n",
        "        mv_fwd, mv_bwd, mode = bidirectional_me(\n",
        "            ref_past, ref_future, frame,\n",
        "            self.block_size, self.search_range,\n",
        "            self.fast, self.lambda_rd\n",
        "        )\n",
        "        \n",
        "        # Motion compensation\n",
        "        pred = motion_compensate_bidirectional(\n",
        "            ref_past, ref_future, mv_fwd, mv_bwd, mode, self.block_size\n",
        "        )\n",
        "        \n",
        "        # Compute residual and map to [0, 255] without hard-clipping:\n",
        "        # residual ∈ [-255, 255] → /2 + 128 → [0.5, 255.5] → round → [0, 255]\n",
        "        residual = frame.astype(np.int16) - pred.astype(np.int16)\n",
        "        residual_img = np.clip(np.round(residual.astype(np.float32) / 2 + 128), 0, 255).astype(np.uint8)\n",
        "        \n",
        "        # Save residual as PNG and encode using transform codec (DCT + quantize + entropy)\n",
        "        residual_fn = f\"{self.args.encoded}_res_{idx:04d}.png\"\n",
        "        Image.fromarray(residual_img).save(residual_fn)\n",
        "        \n",
        "        enc_fn = f\"{self.args.encoded}_{idx:04d}\"\n",
        "        \n",
        "        # Temporarily set args\n",
        "        saved_original = getattr(self.transform_codec.args, 'original', None)\n",
        "        saved_encoded = getattr(self.transform_codec.args, 'encoded', None)\n",
        "        \n",
        "        self.transform_codec.args.original = residual_fn\n",
        "        self.transform_codec.args.encoded = enc_fn\n",
        "        \n",
        "        # Recreate quantizer before encoding\n",
        "        if hasattr(self.args, 'QSS'):\n",
        "            self.transform_codec.args.QSS = self.args.QSS\n",
        "            from scalar_quantization.deadzone_quantization import Deadzone_Quantizer\n",
        "            self.transform_codec.Q = Deadzone_Quantizer(Q_step=self.args.QSS, min_val=0, max_val=255)\n",
        "        \n",
        "        O_bytes = self.transform_codec.encode()\n",
        "        \n",
        "        # Restore args\n",
        "        if saved_original is not None:\n",
        "            self.transform_codec.args.original = saved_original\n",
        "        if saved_encoded is not None:\n",
        "            self.transform_codec.args.encoded = saved_encoded\n",
        "        \n",
        "        self.total_output_size += O_bytes\n",
        "        \n",
        "        # Save motion vectors and mode\n",
        "        np.savez_compressed(\n",
        "            f\"{enc_fn}_mv.npz\",\n",
        "            mv_fwd=mv_fwd,\n",
        "            mv_bwd=mv_bwd,\n",
        "            mode=mode,\n",
        "            ref_past=ref_past_idx,\n",
        "            ref_future=ref_future_idx\n",
        "        )\n",
        "        mv_size = os.path.getsize(f\"{enc_fn}_mv.npz\")\n",
        "        self.total_output_size += mv_size\n",
        "        \n",
        "        # Save frame type\n",
        "        with open(f\"{enc_fn}_type.txt\", 'w') as f:\n",
        "            f.write(f\"B:{ref_past_idx},{ref_future_idx}\")\n",
        "        \n",
        "        # Decode residual to get reconstruction (encoder-side decode for reference)\n",
        "        dec_fn = f\"{self.args.encoded}_dec_{idx:04d}.png\"\n",
        "        saved_encoded = getattr(self.transform_codec.args, 'encoded', None)\n",
        "        saved_decoded = getattr(self.transform_codec.args, 'decoded', None)\n",
        "        \n",
        "        self.transform_codec.args.encoded = enc_fn\n",
        "        self.transform_codec.args.decoded = dec_fn\n",
        "        self._captured_decode_output[0] = None\n",
        "        self.transform_codec.decode()\n",
        "        \n",
        "        self.transform_codec.args.encoded = saved_encoded\n",
        "        self.transform_codec.args.decoded = saved_decoded\n",
        "        \n",
        "        # Undo mapping: (pixel - 128) * 2; use captured output if available\n",
        "        if self._captured_decode_output[0] is not None:\n",
        "            residual_img_dec = self._captured_decode_output[0]\n",
        "        elif os.path.exists(dec_fn):\n",
        "            residual_img_dec = np.array(Image.open(dec_fn).convert(\"RGB\"))\n",
        "        else:\n",
        "            raise FileNotFoundError(\n",
        "                f\"Decoded residual not found at {dec_fn}. \"\n",
        "                \"The transform codec's decode() did not write the expected output.\"\n",
        "            )\n",
        "        residual_rec = (residual_img_dec.astype(np.int16) - 128) * 2\n",
        "        \n",
        "        # Reconstruct and cache\n",
        "        recon = np.clip(pred.astype(np.int16) + residual_rec, 0, 255).astype(np.uint8)\n",
        "        decoded_frames[idx] = recon\n",
        "        \n",
        "        mode_stats = [np.sum(mode == i) for i in range(3)]\n",
        "        logging.info(f\"  B-frame {idx}: residual={O_bytes} bytes, mv={mv_size} bytes, \"\n",
        "                    f\"modes(fwd/bwd/bi)={mode_stats}\")\n",
        "\n",
        "    def decode(self):\n",
        "        \"\"\"Decode MCTF encoded video.\"\"\"\n",
        "        logging.debug(\"trace\")\n",
        "        \n",
        "        # Read encoding metadata if available (makes decode self-contained)\n",
        "        meta = f\"{self.args.encoded}_meta.txt\"\n",
        "        if os.path.exists(meta):\n",
        "            with open(meta, \"r\") as f:\n",
        "                self.original_prefix = f.readline().strip()\n",
        "                self.N_frames = int(f.readline().strip())\n",
        "                self.height = int(f.readline().strip())\n",
        "                self.width = int(f.readline().strip())\n",
        "                self._meta_BPP = float(f.readline().strip())\n",
        "                line = f.readline().strip()\n",
        "                if line:\n",
        "                    self.total_output_size = int(line)\n",
        "        \n",
        "        # First, scan all frames to determine decoding order\n",
        "        frame_info = {}\n",
        "        idx = 0\n",
        "        while True:\n",
        "            type_fn = f\"{self.args.encoded}_{idx:04d}_type.txt\"\n",
        "            \n",
        "            if not os.path.exists(type_fn):\n",
        "                if idx == 0:\n",
        "                    logging.error(\"No encoded frames found\")\n",
        "                    return 0\n",
        "                break\n",
        "            \n",
        "            with open(type_fn, 'r') as f:\n",
        "                frame_type = f.read().strip()\n",
        "            \n",
        "            frame_info[idx] = {\n",
        "                'type': frame_type,\n",
        "                'display_order': idx\n",
        "            }\n",
        "            idx += 1\n",
        "        \n",
        "        total_frames = len(frame_info)\n",
        "        logging.info(f\"Found {total_frames} encoded frames\")\n",
        "        \n",
        "        # Decode frames in dependency order (handles hierarchical B-frames)\n",
        "        # Keep decoding frames whose references are ready\n",
        "        decoded_frames = {}\n",
        "        remaining_frames = set(range(total_frames))\n",
        "        \n",
        "        while remaining_frames:\n",
        "            progress = False\n",
        "            \n",
        "            for idx in list(remaining_frames):\n",
        "                frame_type = frame_info[idx]['type']\n",
        "                can_decode = False\n",
        "                \n",
        "                if frame_type == \"I\":\n",
        "                    # I-frames have no dependencies\n",
        "                    can_decode = True\n",
        "                \n",
        "                elif frame_type.startswith(\"P:\"):\n",
        "                    # P-frames depend on one reference\n",
        "                    ref_idx = int(frame_type.split(\":\")[1])\n",
        "                    can_decode = ref_idx in decoded_frames\n",
        "                \n",
        "                elif frame_type.startswith(\"B:\"):\n",
        "                    # B-frames depend on two references\n",
        "                    refs = frame_type.split(\":\")[1].split(\",\")\n",
        "                    ref_past = int(refs[0])\n",
        "                    ref_future = int(refs[1])\n",
        "                    can_decode = (ref_past in decoded_frames and ref_future in decoded_frames)\n",
        "                \n",
        "                # Decode if ready\n",
        "                if can_decode:\n",
        "                    if frame_type == \"I\":\n",
        "                        self._decode_i_frame(idx, decoded_frames)\n",
        "                    elif frame_type.startswith(\"P:\"):\n",
        "                        ref_idx = int(frame_type.split(\":\")[1])\n",
        "                        self._decode_p_frame(idx, ref_idx, decoded_frames)\n",
        "                    elif frame_type.startswith(\"B:\"):\n",
        "                        refs = frame_type.split(\":\")[1].split(\",\")\n",
        "                        ref_past = int(refs[0])\n",
        "                        ref_future = int(refs[1])\n",
        "                        self._decode_b_frame(idx, ref_past, ref_future, decoded_frames)\n",
        "                    \n",
        "                    remaining_frames.remove(idx)\n",
        "                    progress = True\n",
        "            \n",
        "            # Check for deadlock\n",
        "            if not progress:\n",
        "                raise RuntimeError(f\"Cannot decode remaining frames {remaining_frames} - \"\n",
        "                                   f\"circular dependency or missing references\")\n",
        "        \n",
        "        logging.info(f\"\\n{'='*60}\")\n",
        "        logging.info(f\"DECODING COMPLETE\")\n",
        "        logging.info(f\"{'='*60}\")\n",
        "        logging.info(f\"Total frames decoded: {len(decoded_frames)}\")\n",
        "        \n",
        "        # Write all decoded frames to disk with consistent naming\n",
        "        # (guarantees files exist at the expected paths for RMSE and ffmpeg)\n",
        "        decoded_prefix = getattr(self.args, 'decoded', '/tmp/decoded')\n",
        "        if decoded_prefix.endswith('.png'):\n",
        "            decoded_prefix = decoded_prefix[:-4]\n",
        "        for idx in range(len(decoded_frames)):\n",
        "            out_fn = f\"{decoded_prefix}_{idx:04d}.png\"\n",
        "            Image.fromarray(decoded_frames[idx]).save(out_fn)\n",
        "        logging.info(f\"Wrote {len(decoded_frames)} frames to {decoded_prefix}_XXXX.png\")\n",
        "        \n",
        "        # Calculate quality metrics (RMSE) if original frames are available\n",
        "        try:\n",
        "            from information_theory import distortion\n",
        "            \n",
        "            total_RMSE = 0\n",
        "            frames_compared = 0\n",
        "            \n",
        "            for idx in range(len(decoded_frames)):\n",
        "                original_fn = f\"{self.original_prefix}_{idx:04d}.png\"\n",
        "                decoded_fn = f\"{decoded_prefix}_{idx:04d}.png\"\n",
        "                \n",
        "                if os.path.exists(original_fn) and os.path.exists(decoded_fn):\n",
        "                    original_img = np.array(Image.open(original_fn).convert(\"RGB\"))\n",
        "                    decoded_img = np.array(Image.open(decoded_fn).convert(\"RGB\"))\n",
        "                    \n",
        "                    frame_RMSE = distortion.RMSE(original_img, decoded_img)\n",
        "                    total_RMSE += frame_RMSE\n",
        "                    frames_compared += 1\n",
        "                    \n",
        "                    if idx < 3 or idx == len(decoded_frames) - 1:  # Log first 3 and last frame\n",
        "                        logging.info(f\"  Frame {idx} RMSE: {frame_RMSE:.4f}\")\n",
        "            \n",
        "            if frames_compared > 0:\n",
        "                avg_RMSE = total_RMSE / frames_compared\n",
        "                \n",
        "                # Calculate BPP from encoding metadata\n",
        "                BPP = 0\n",
        "                if hasattr(self, 'total_output_size') and self.total_output_size > 0 and hasattr(self, 'width') and hasattr(self, 'height'):\n",
        "                    total_pixels = frames_compared * self.width * self.height\n",
        "                    BPP = (self.total_output_size * 8) / total_pixels\n",
        "                elif hasattr(self, '_meta_BPP') and self._meta_BPP > 0:\n",
        "                    BPP = self._meta_BPP\n",
        "                else:\n",
        "                    logging.warning(\"Could not determine BPP from encoding metadata\")\n",
        "                \n",
        "                lrd = getattr(self, 'lambda_rd', 1.0)\n",
        "                J = avg_RMSE + lrd * BPP\n",
        "                \n",
        "                logging.info(f\"\\n{'='*60}\")\n",
        "                logging.info(f\"QUALITY METRICS\")\n",
        "                logging.info(f\"{'='*60}\")\n",
        "                logging.info(f\"Frames compared: {frames_compared}\")\n",
        "                logging.info(f\"Average RMSE (D): {avg_RMSE:.6f}\")\n",
        "                logging.info(f\"Bits Per Pixel (R): {BPP:.6f}\")\n",
        "                logging.info(f\"λ (lambda_rd): {lrd:.4f}\")\n",
        "                logging.info(f\"Rate-Distortion Cost (J = D + λ·R): {J:.6f}\")\n",
        "                logging.info(f\"{'='*60}\\n\")\n",
        "        \n",
        "        except ImportError:\n",
        "            logging.warning(\"information_theory module not available, skipping RMSE calculation\")\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"Error calculating metrics: {e}\")\n",
        "        \n",
        "        # Create output video\n",
        "        logging.info(\"Creating output video...\")\n",
        "        \n",
        "        # Use ffmpeg to combine frames with optimized settings\n",
        "        import subprocess\n",
        "        try:\n",
        "            # Verify decoded frames actually exist before calling ffmpeg\n",
        "            first_frame = f\"{decoded_prefix}_0000.png\"\n",
        "            logging.info(f\"Decoded prefix: {decoded_prefix}\")\n",
        "            logging.info(f\"First frame exists? {os.path.exists(first_frame)}\")\n",
        "            if not os.path.exists(first_frame):\n",
        "                logging.error(f\"Cannot create video: first decoded frame not found at {first_frame}\")\n",
        "                return 0\n",
        "            \n",
        "            output_mp4 = f'{decoded_prefix}.mp4'\n",
        "            cmd = [\n",
        "                'ffmpeg', '-y',\n",
        "                '-framerate', '30',\n",
        "                '-i', f'{decoded_prefix}_%04d.png',\n",
        "                '-c:v', 'libx264',\n",
        "                '-crf', '18',  # Near-lossless quality (0=lossless, 51=worst, 18=visually lossless)\n",
        "                '-preset', 'medium',  # Encoding speed (slower = better compression)\n",
        "                '-pix_fmt', 'yuv420p',\n",
        "                output_mp4\n",
        "            ]\n",
        "            \n",
        "            # Debug: show command\n",
        "            logging.info(f\"Running ffmpeg command: {' '.join(cmd)}\")\n",
        "            \n",
        "            result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "            \n",
        "            # Get output video size\n",
        "            if os.path.exists(output_mp4):\n",
        "                mp4_size = os.path.getsize(output_mp4)\n",
        "                logging.info(f\"Video saved to {output_mp4}\")\n",
        "                logging.info(f\"Output MP4 size: {mp4_size} bytes ({mp4_size/1024/1024:.2f} MB)\")\n",
        "                \n",
        "                # Compare with encoded size (if available from encoding metadata)\n",
        "                if hasattr(self, 'total_output_size') and self.total_output_size > 0:\n",
        "                    ratio = mp4_size / self.total_output_size\n",
        "                    logging.info(f\"MP4 vs Encoded ratio: {ratio:.2f}x\")\n",
        "                    if ratio > 2:\n",
        "                        logging.warning(f\"MP4 is {ratio:.2f}x larger than encoded data!\")\n",
        "                else:\n",
        "                    # Try to use metadata loaded at start of decode()\n",
        "                    if hasattr(self, '_meta_BPP') and self._meta_BPP > 0 and hasattr(self, 'width') and hasattr(self, 'height') and hasattr(self, 'N_frames'):\n",
        "                        total_pixels = self.N_frames * self.height * self.width\n",
        "                        encoded_size = int((self._meta_BPP * total_pixels) / 8)\n",
        "                        if encoded_size > 0:\n",
        "                            ratio = mp4_size / encoded_size\n",
        "                            logging.info(f\"Encoded data size: {encoded_size} bytes ({encoded_size/1024/1024:.2f} MB)\")\n",
        "                            logging.info(f\"MP4 vs Encoded ratio: {ratio:.2f}x\")\n",
        "                            if ratio > 2:\n",
        "                                logging.info(f\"NOTE: MP4 is {ratio:.2f}x larger - this is normal for H.264 re-encoding\")\n",
        "                    else:\n",
        "                        logging.debug(\"Could not calculate encoded size for comparison\")\n",
        "            \n",
        "            # Show ffmpeg output if debugging\n",
        "            if result.stderr:\n",
        "                logging.debug(f\"FFmpeg output: {result.stderr}\")\n",
        "                \n",
        "        except subprocess.CalledProcessError as e:\n",
        "            logging.error(f\"Failed to create video: {e}\")\n",
        "            logging.error(f\"FFmpeg stderr: {e.stderr}\")\n",
        "            logging.error(f\"FFmpeg stdout: {e.stdout}\")\n",
        "        except FileNotFoundError:\n",
        "            logging.warning(\"ffmpeg not found, skipping video creation\")\n",
        "        \n",
        "        return 0\n",
        "\n",
        "    def _decode_i_frame(self, idx, decoded_frames):\n",
        "        \"\"\"Decode I-frame.\"\"\"\n",
        "        enc_fn = f\"{self.args.encoded}_{idx:04d}\"\n",
        "        dec_fn = f\"{getattr(self.args, 'decoded', '/tmp/decoded')}_{idx:04d}.png\"\n",
        "        \n",
        "        logging.info(f\"Decoding I-frame {idx}\")\n",
        "        saved_encoded = self.transform_codec.args.encoded\n",
        "        saved_decoded = self.transform_codec.args.decoded\n",
        "        \n",
        "        self.transform_codec.args.encoded = enc_fn\n",
        "        self.transform_codec.args.decoded = dec_fn\n",
        "        self.transform_codec.decode()\n",
        "        \n",
        "        self.transform_codec.args.encoded = saved_encoded\n",
        "        self.transform_codec.args.decoded = saved_decoded\n",
        "        \n",
        "        img = np.array(Image.open(dec_fn).convert(\"RGB\"))\n",
        "        decoded_frames[idx] = img\n",
        "\n",
        "    def _decode_p_frame(self, idx, ref_idx, decoded_frames):\n",
        "        \"\"\"Decode P-frame using VCF transform.\"\"\"\n",
        "        logging.info(f\"Decoding P-frame {idx} (ref={ref_idx})\")\n",
        "        \n",
        "        enc_fn = f\"{self.args.encoded}_{idx:04d}\"\n",
        "        \n",
        "        # Load motion vectors\n",
        "        mv_data = np.load(f\"{enc_fn}_mv.npz\")\n",
        "        mv_field = mv_data['mv']\n",
        "        \n",
        "        # Decode residual using transform codec\n",
        "        residual_fn = f\"{self.args.encoded}_dec_res_{idx:04d}.png\"\n",
        "        saved_encoded = self.transform_codec.args.encoded\n",
        "        saved_decoded = self.transform_codec.args.decoded\n",
        "        \n",
        "        self.transform_codec.args.encoded = enc_fn\n",
        "        self.transform_codec.args.decoded = residual_fn\n",
        "        self.transform_codec.decode()\n",
        "        \n",
        "        self.transform_codec.args.encoded = saved_encoded\n",
        "        self.transform_codec.args.decoded = saved_decoded\n",
        "        \n",
        "        # Undo /2+128 mapping: (pixel - 128) * 2\n",
        "        residual = (np.array(Image.open(residual_fn).convert(\"RGB\")).astype(np.int16) - 128) * 2\n",
        "        \n",
        "        # Motion compensation\n",
        "        ref_frame = decoded_frames[ref_idx]\n",
        "        pred = motion_compensate(ref_frame, mv_field, self.block_size)\n",
        "        \n",
        "        # Reconstruct\n",
        "        recon = np.clip(pred.astype(np.int16) + residual, 0, 255).astype(np.uint8)\n",
        "        decoded_frames[idx] = recon\n",
        "\n",
        "    def _decode_b_frame(self, idx, ref_past_idx, ref_future_idx, decoded_frames):\n",
        "        \"\"\"Decode B-frame using VCF transform.\"\"\"\n",
        "        logging.info(f\"Decoding B-frame {idx} (refs={ref_past_idx},{ref_future_idx})\")\n",
        "        \n",
        "        enc_fn = f\"{self.args.encoded}_{idx:04d}\"\n",
        "        \n",
        "        # Load motion vectors and mode\n",
        "        mv_data = np.load(f\"{enc_fn}_mv.npz\")\n",
        "        mv_fwd = mv_data['mv_fwd']\n",
        "        mv_bwd = mv_data['mv_bwd']\n",
        "        mode = mv_data['mode']\n",
        "        \n",
        "        # Decode residual using transform codec\n",
        "        residual_fn = f\"{self.args.encoded}_dec_res_{idx:04d}.png\"\n",
        "        saved_encoded = self.transform_codec.args.encoded\n",
        "        saved_decoded = self.transform_codec.args.decoded\n",
        "        \n",
        "        self.transform_codec.args.encoded = enc_fn\n",
        "        self.transform_codec.args.decoded = residual_fn\n",
        "        self.transform_codec.decode()\n",
        "        \n",
        "        self.transform_codec.args.encoded = saved_encoded\n",
        "        self.transform_codec.args.decoded = saved_decoded\n",
        "        \n",
        "        # Undo /2+128 mapping: (pixel - 128) * 2\n",
        "        residual = (np.array(Image.open(residual_fn).convert(\"RGB\")).astype(np.int16) - 128) * 2\n",
        "        \n",
        "        # Motion compensation\n",
        "        ref_past = decoded_frames[ref_past_idx]\n",
        "        ref_future = decoded_frames[ref_future_idx]\n",
        "        pred = motion_compensate_bidirectional(\n",
        "            ref_past, ref_future, mv_fwd, mv_bwd, mode, self.block_size\n",
        "        )\n",
        "        \n",
        "        # Reconstruct\n",
        "        recon = np.clip(pred.astype(np.int16) + residual, 0, 255).astype(np.uint8)\n",
        "        decoded_frames[idx] = recon\n",
        "\n",
        "# =============================================================================\n",
        "# Main\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main.main(parser.parser, logging, CoDec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install -r ../requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Help about basic functionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 ../src/MCTF.py -h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Help to encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 ../src/MCTF.py encode -h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo 1: Encoding a Remote Video\n",
        "\n",
        "We'll encode the **\"mobile\"** test sequence (352x288, 30fps, 300 frames). This is a standard test video with multiple moving objects (calendar, toy train, ball) — challenging for motion estimation.\n",
        "\n",
        "**Parameters used:**\n",
        "- `gop_size=16`: each GOP has 16 frames (1 I-frame + 1 P-frame + 14 B-frames)\n",
        "- `num_gops=2`: encode 32 frames total\n",
        "- Default QSS (quantization), default block size (16x16), default search range (32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encode and decoding a remote video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video src=\"http://www.hpca.ual.es/~vruiz/videos/mobile_352x288x30x420x300.mp4\" controls  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Video(\"http://www.hpca.ual.es/~vruiz/videos/mobile_352x288x30x420x300.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use -o for original video, --num_gops to specify how many GOPs to encode\n",
        "# Total frames = gop_size * num_gops (16 * 2 = 32 frames)\n",
        "!python3 ../src/MCTF.py encode -o http://www.hpca.ual.es/~vruiz/videos/mobile_352x288x30x420x300.mp4 --gop_size 16 --num_gops 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 ../src/MCTF.py decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Video is automatically created at /tmp/decoded.mp4\n",
        "Video(\"../tmp/encoded.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo 2: Encoding a Local Video\n",
        "\n",
        "Now we use the **\"coastguard\"** sequence — a surveillance-style video with a boat moving across water. The water ripples create complex textures that are harder to predict.\n",
        "\n",
        "We encode **80 frames** (5 GOPs x 16 frames each) to see how the codec handles longer sequences and multiple GOP boundaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encode and decode a local video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget http://www.hpca.ual.es/~vruiz/videos/coastguard_352x288x30x420x300.avi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encodes 80 frames (gop_size=16 * num_gops=5)\n",
        "!python3 ../src/MCTF.py encode -o coastguard_352x288x30x420x300.avi --gop_size 16 --num_gops 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 ../src/MCTF.py decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Video(\"../tmp/encoded.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Default encoding and decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!rm /tmp/encoded* /tmp/decoded* 2>/dev/null; echo \"Cleaned /tmp files\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 ../src/MCTF.py encode -o \"your_video\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 ../src/MCTF.py decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Video(\"/tmp/decoded.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo 3: Hierarchical B-frames\n",
        "\n",
        "Here we enable `--hierarchical` to use the tree-structured B-frame ordering. Compare the **BPP** (bits per pixel) and **RMSE** in the output with the simple B-frame demo above.\n",
        "\n",
        "**Expected result:** Hierarchical should produce **lower BPP** (better compression) because each B-frame references temporally closer frames, yielding smaller motion vectors and residuals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using hierarchical B-frame structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 ../src/MCTF.py encode -o coastguard_352x288x30x420x300.avi --gop_size 16 --num_gops 5 --hierarchical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 ../src/MCTF.py decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Video(\"/tmp/decoded.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo 4: Fast Motion Estimation (Diamond Search)\n",
        "\n",
        "The `--fast` flag switches from **exhaustive search** (tests all positions) to **diamond search** (follows the gradient).\n",
        "\n",
        "| | Exhaustive | Diamond (`--fast`) |\n",
        "|-|-----------|-------------------|\n",
        "| Complexity | $O(\\text{sr}^2)$ per block | $O(\\log \\text{sr})$ per block |\n",
        "| For sr=32 | 4,225 SAD evaluations | ~20-40 SAD evaluations |\n",
        "| Quality | Optimal | ~95% of optimal |\n",
        "| Speed | Slow | **10-50x faster** |\n",
        "\n",
        "**Expected result:** Very similar quality (RMSE) but **much faster** encoding time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using fast motion estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 ../src/MCTF.py encode -o coastguard_352x288x30x420x300.avi --gop_size 16 --num_gops 5 --fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 ../src/MCTF.py decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Video(\"/tmp/decoded.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo 5: Effect of Quantization Step Size (QSS)\n",
        "\n",
        "The **QSS** parameter controls the trade-off between quality and compression:\n",
        "\n",
        "$$\\text{quantized} = \\text{sign}(x) \\cdot \\left\\lfloor \\frac{|x|}{\\text{QSS}} \\right\\rfloor$$\n",
        "\n",
        "| QSS | Effect on coefficients | Quality | File size |\n",
        "|-----|----------------------|---------|-----------|\n",
        "| **16** (low) | Keeps more detail | **High** (low RMSE) | Larger |\n",
        "| **32** (medium) | Balanced | Medium | Medium |\n",
        "| **64** (high) | Aggressive zeroing | **Low** (high RMSE) | Smaller |\n",
        "\n",
        "We encode the same video with QSS=16 and QSS=64 to demonstrate this trade-off visually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Different quantization steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lower QSS = better quality\n",
        "!python3 ../src/MCTF.py encode -o coastguard_352x288x30x420x300.avi --gop_size 16 --num_gops 5 -q 16 --fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 ../src/MCTF.py decode -q 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Video(\"/tmp/decoded.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Higher QSS = more compression\n",
        "!python3 ../src/MCTF.py encode -o coastguard_352x288x30x420x300.avi --gop_size 16 --num_gops 5 -q 64 --fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 ../src/MCTF.py decode -q 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Video(\"/tmp/decoded.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo 6: Hierarchical vs Simple B-frames — Quantitative Comparison\n",
        "\n",
        "This experiment runs **both** configurations with identical parameters and compares the **BPP** numerically. This is the most rigorous comparison in the notebook:\n",
        "\n",
        "- Same video, same QSS (32), same search (`--fast`), same GOP structure\n",
        "- Only difference: `--hierarchical` flag on/off\n",
        "- We extract BPP from the encoder output and display a comparison table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hierarchical vs Non-Hierarchical B-frames Comparison\n",
        "\n",
        "This comparison demonstrates the compression efficiency difference between simple (sequential) and hierarchical B-frame structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up previous encodings\n",
        "!rm -f /tmp/encoded_* /tmp/decoded_*\n",
        "\n",
        "import re\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# Encode WITHOUT hierarchical B-frames\n",
        "print(\"=\" * 70)\n",
        "print(\"ENCODING: Simple (Non-Hierarchical) B-frames\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = subprocess.run(\n",
        "    ['python3', '../src/MCTF.py', 'encode', \n",
        "     '-o', 'coastguard_352x288x30x420x300.avi',\n",
        "     '--gop_size', '16',\n",
        "     '--num_gops', '5',\n",
        "     '-q', '32',\n",
        "     '--fast',\n",
        "     '-O', '/tmp/encoded_simple'],\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "print(f\"result stdout {result.stdout}\")\n",
        "print(f\"result stderr {result.stderr}\")\n",
        "\n",
        "# Extract BPP from output\n",
        "bpp_line = [l for l in result.stderr.split('\\n') if 'Bits Per Pixel (BPP):' in l][0]\n",
        "print(f\"Found line: {bpp_line}\")  # Debug\n",
        "\n",
        "bpp_simple = float(bpp_line.split(':')[-1].strip())  \n",
        "\n",
        "print(f\"\\n✓ Hierarchical B-frames BPP: {bpp_simple:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# Encode WITH hierarchical B-frames\n",
        "print(\"=\" * 70)\n",
        "print(\"ENCODING: Hierarchical B-frames\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = subprocess.run(\n",
        "    ['python3', '../src/MCTF.py', 'encode', \n",
        "     '-o', 'coastguard_352x288x30x420x300.avi',\n",
        "     '--gop_size', '16',\n",
        "     '--num_gops', '5',\n",
        "     '-q', '32',\n",
        "     '--fast',\n",
        "     '--hierarchical',\n",
        "     '-O', '/tmp/encoded_hierarchical'],\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "print(f\"result stdout {result.stdout}\")\n",
        "print(f\"result stderr {result.stderr}\")\n",
        "\n",
        "# Extract BPP from output\n",
        "bpp_line = [l for l in result.stderr.split('\\n') if 'Bits Per Pixel (BPP):' in l][0]\n",
        "print(f\"Found line: {bpp_line}\")  \n",
        "bpp_hierarchical = float(bpp_line.split(':')[-1].strip())\n",
        "\n",
        "print(f\"\\n✓ Hierarchical B-frames BPP: {bpp_hierarchical:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display comparison table\n",
        "import pandas as pd\n",
        "\n",
        "if bpp_simple and bpp_hierarchical:\n",
        "    improvement = ((bpp_simple - bpp_hierarchical) / bpp_simple) * 100\n",
        "    \n",
        "    comparison_data = {\n",
        "        'Mode': ['Simple (Non-Hierarchical)', 'Hierarchical'],\n",
        "        'BPP': [f'{bpp_simple:.6f}', f'{bpp_hierarchical:.6f}'],\n",
        "        'Bytes/Frame (estimated)': [\n",
        "            f'{(bpp_simple * 352 * 288 / 8):.2f}',\n",
        "            f'{(bpp_hierarchical * 352 * 288 / 8):.2f}'\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    df = pd.DataFrame(comparison_data)\n",
        "    display(df)\n",
        "    \n",
        "    print(f\"\\n{'=' * 70}\")\n",
        "    print(f\"COMPRESSION COMPARISON RESULTS\")\n",
        "    print(f\"{'=' * 70}\")\n",
        "    print(f\"Simple B-frames:        {bpp_simple:.6f} bpp\")\n",
        "    print(f\"Hierarchical B-frames:  {bpp_hierarchical:.6f} bpp\")\n",
        "    print(f\"{'=' * 70}\")\n",
        "    \n",
        "    if improvement > 0:\n",
        "        print(f\"✓ Hierarchical is {improvement:.2f}% BETTER (lower BPP)\")\n",
        "        print(f\"  → Savings: {bpp_simple - bpp_hierarchical:.6f} bpp\")\n",
        "    else:\n",
        "        print(f\"✗ Hierarchical is {abs(improvement):.2f}% WORSE (higher BPP)\")\n",
        "    \n",
        "    print(f\"\\nWhy hierarchical is better:\")\n",
        "    print(\"  • B-frames reference temporally closer frames\")\n",
        "    print(\"  • Smaller motion vectors (less to encode)\")\n",
        "    print(\"  • More accurate prediction (smaller residuals)\")\n",
        "    print(\"  • Better rate-distortion performance overall\")\n",
        "else:\n",
        "    print(\"⚠ Could not extract BPP values. Please check the encoding output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Decode hierarchical version for playback\n",
        "!python3 ../src/MCTF.py decode -i /tmp/encoded_hierarchical -O /tmp/decoded_hierarchical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hierarchical result playback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Video(\"/tmp/decoded_hierarchical.mp4\", width=640)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Summary and Conclusions\n",
        "\n",
        "### What we built\n",
        "\n",
        "A complete **Motion-Compensated Temporal Filtering (MCTF)** video codec that:\n",
        "\n",
        "1. **Exploits temporal redundancy** via block-based motion estimation and compensation\n",
        "2. **Supports three frame types** (I, P, B) with mode selection for B-frames\n",
        "3. **Offers two GOP structures** — simple and hierarchical — with measurable compression gains from the hierarchical approach\n",
        "4. **Provides fast and exhaustive ME** options with parallelized execution\n",
        "5. **Integrates with VCF** spatial transforms (2D-DCT) for residual coding\n",
        "6. **Uses Rate-Distortion Optimization** with $\\lambda$ to balance quality vs. compression\n",
        "\n",
        "### Key Results\n",
        "\n",
        "| Feature | Impact |\n",
        "|---------|--------|\n",
        "| B-frames vs I-only | **Large** BPP reduction (temporal prediction removes most redundancy) |\n",
        "| Hierarchical vs Simple GOP | **Moderate** BPP reduction (~5-15% depending on content) |\n",
        "| Diamond vs Exhaustive ME | **Negligible** quality loss, **significant** speed-up |\n",
        "| Lower QSS | Better quality, higher BPP (rate-distortion trade-off) |\n",
        "\n",
        "### Relation to Industry Standards\n",
        "\n",
        "Our codec implements the **same core ideas** used in H.264/AVC and H.265/HEVC:\n",
        "\n",
        "| Our codec | H.264/H.265 |\n",
        "|-----------|------------|\n",
        "| Block matching (16x16) | Variable block sizes (4x4 to 64x64) |\n",
        "| Diamond search | Multiple search algorithms + fractional-pel |\n",
        "| 2D-DCT | Integer DCT (4x4, 8x8, 16x16, 32x32) |\n",
        "| Deadzone quantizer | Rate-dependent QP with scaling matrices |\n",
        "| Exp-Golomb MV coding | CABAC / CAVLC adaptive arithmetic coding |\n",
        "| $J = D + \\lambda R$ | Same Lagrangian RDO framework |\n",
        "\n",
        "> **Key takeaway:** Even our simplified codec achieves meaningful compression, demonstrating that the fundamental ideas — prediction, transform, quantization, and entropy coding — are what make video compression work.\n",
        "\n",
        "---\n",
        "\n",
        "*Authors: Youssef Zerbouh, Hamza El Qadiri -- February 2026*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
